{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e98e3307-e0a8-41ec-bcae-2e722ad0f39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError, RootMeanSquaredError\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3bdcff5-b225-4302-9934-f36a7e7d2424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging to both console and file\n",
    "log_filename = 'training_logs.txt'\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename),  # Log to a file\n",
    "        logging.StreamHandler()              # Log to console\n",
    "    ]\n",
    ")\n",
    "# Load preprocessed data\n",
    "def load_preprocessed_data():\n",
    "    logging.info(\"Loading preprocessed data...\")\n",
    "    input_sequences_train = np.load('input_sequences_train.npy')\n",
    "    next_step_targets_train = np.load('next_step_targets_train.npy')\n",
    "    logging.info(\"Data loaded successfully.\")\n",
    "    return input_sequences_train, next_step_targets_train\n",
    "\n",
    "# Define LSTM model with metric accuracy\n",
    "def build_lstm_model_acc(time_steps, input_shape):\n",
    "    logging.info(\"Building LSTM model with accuracy metric...\")\n",
    "    lstm_acc = Sequential()\n",
    "    lstm_acc.add(LSTM(64, return_sequences=True, input_shape=(time_steps, input_shape)))\n",
    "    lstm_acc.add(Dropout(0.2))\n",
    "    lstm_acc.add(LSTM(64, return_sequences=False))\n",
    "    lstm_acc.add(Dense(input_shape, activation='sigmoid'))\n",
    "    lstm_acc.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    logging.info(\"LSTM model built successfully.\")\n",
    "    return lstm_acc\n",
    "\n",
    "# Train LSTM model with metric accuracy\n",
    "def train_lstm_model_acc(time_steps, input_sequences_train, next_step_targets_train):\n",
    "    logging.info(\"Starting training of LSTM model with accuracy metric...\")\n",
    "    lstm_acc = build_lstm_model_acc(time_steps, input_sequences_train.shape[2])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
    "    checkpoint = ModelCheckpoint('best_lstm_model_acc.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "    lstm_acc.fit(input_sequences_train, next_step_targets_train, epochs=20, validation_split=0.1, callbacks=[early_stopping, checkpoint])\n",
    "    lstm_acc.save('lstm_model_acc.keras')\n",
    "    logging.info(\"LSTM model trained and saved successfully.\")\n",
    "    return lstm_acc\n",
    "\n",
    "# Define GRU model with metric accuracy\n",
    "def build_gru_model_acc(time_steps, input_shape):\n",
    "    logging.info(\"Building GRU model with accuracy metric...\")\n",
    "    gru_acc = Sequential()\n",
    "    gru_acc.add(GRU(64, return_sequences=True, input_shape=(time_steps, input_shape)))\n",
    "    gru_acc.add(Dropout(0.2))\n",
    "    gru_acc.add(GRU(64, return_sequences=False))\n",
    "    gru_acc.add(Dense(input_shape, activation='sigmoid'))\n",
    "    gru_acc.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    logging.info(\"GRU model built successfully.\")\n",
    "    return gru_acc\n",
    "\n",
    "# Train GRU model with metric accuracy\n",
    "def train_gru_model_acc(time_steps, input_sequences_train, next_step_targets_train):\n",
    "    logging.info(\"Starting training of GRU model with accuracy metric...\")\n",
    "    gru_acc = build_gru_model_acc(time_steps, input_sequences_train.shape[2])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
    "    checkpoint = ModelCheckpoint('best_gru_model_acc.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "    gru_acc.fit(input_sequences_train, next_step_targets_train, epochs=20, validation_split=0.1, callbacks=[early_stopping, checkpoint])\n",
    "    gru_acc.save('gru_model_acc.keras')\n",
    "    logging.info(\"GRU model trained and saved successfully.\")\n",
    "    return gru_acc\n",
    "\n",
    "# Define LSTM model with metric MAE\n",
    "def build_lstm_model_mae(time_steps, input_shape):\n",
    "    logging.info(\"Building LSTM model with MAE metric...\")\n",
    "    lstm_mae = Sequential()\n",
    "    lstm_mae.add(LSTM(64, return_sequences=True, input_shape=(time_steps, input_shape)))\n",
    "    lstm_mae.add(Dropout(0.2))\n",
    "    lstm_mae.add(LSTM(64, return_sequences=False))\n",
    "    lstm_mae.add(Dense(input_shape, activation='sigmoid'))\n",
    "    lstm_mae.compile(optimizer='adam', loss='mean_squared_error', metrics=[MeanAbsoluteError()])\n",
    "    logging.info(\"LSTM model with MAE built successfully.\")\n",
    "    return lstm_mae\n",
    "\n",
    "# Train LSTM model with metric MAE\n",
    "def train_lstm_model_mae(time_steps, input_sequences_train, next_step_targets_train):\n",
    "    logging.info(\"Starting training of LSTM model with MAE metric...\")\n",
    "    lstm_model_mae = build_lstm_model_mae(time_steps, input_sequences_train.shape[2])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
    "    checkpoint = ModelCheckpoint('best_lstm_model_mae.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "    lstm_model_mae.fit(input_sequences_train, next_step_targets_train, epochs=20, validation_split=0.1, callbacks=[early_stopping, checkpoint])\n",
    "    lstm_model_mae.save('lstm_model_mae.keras')\n",
    "    logging.info(\"LSTM model with MAE trained and saved successfully.\")\n",
    "    return lstm_model_mae\n",
    "\n",
    "# Define GRU model with metric MAE\n",
    "def build_gru_model_mae(time_steps, input_shape):\n",
    "    logging.info(\"Building GRU model with MAE metric...\")\n",
    "    gru_mae = Sequential()\n",
    "    gru_mae.add(GRU(64, return_sequences=True, input_shape=(time_steps, input_shape)))\n",
    "    gru_mae.add(Dropout(0.2))\n",
    "    gru_mae.add(GRU(64, return_sequences=False))\n",
    "    gru_mae.add(Dense(input_shape, activation='sigmoid'))\n",
    "    gru_mae.compile(optimizer='adam', loss='mean_squared_error', metrics=[MeanAbsoluteError()])\n",
    "    logging.info(\"GRU model with MAE built successfully.\")\n",
    "    return gru_mae\n",
    "\n",
    "# Train GRU model with metric MAE\n",
    "def train_gru_model_mae(time_steps, input_sequences_train, next_step_targets_train):\n",
    "    logging.info(\"Starting training of GRU model with MAE metric...\")\n",
    "    gru_model_mae = build_gru_model_mae(time_steps, input_sequences_train.shape[2])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
    "    checkpoint = ModelCheckpoint('best_gru_model_mae.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "    gru_model_mae.fit(input_sequences_train, next_step_targets_train, epochs=20, validation_split=0.1, callbacks=[early_stopping, checkpoint])\n",
    "    gru_model_mae.save('gru_model_mae.keras')\n",
    "    logging.info(\"GRU model with MAE trained and saved successfully.\")\n",
    "    return gru_model_mae\n",
    "\n",
    "# Define LSTM model with metric RMSE\n",
    "def build_lstm_model_rmse(time_steps, input_shape):\n",
    "    logging.info(\"Building LSTM model with RMSE metric...\")\n",
    "    lstm_rmse = Sequential()\n",
    "    lstm_rmse.add(LSTM(64, return_sequences=True, input_shape=(time_steps, input_shape)))\n",
    "    lstm_rmse.add(Dropout(0.2))\n",
    "    lstm_rmse.add(LSTM(64, return_sequences=False))\n",
    "    lstm_rmse.add(Dense(input_shape, activation='sigmoid'))\n",
    "    lstm_rmse.compile(optimizer='adam', loss='mean_squared_error', metrics=[RootMeanSquaredError()])\n",
    "    logging.info(\"LSTM model with RMSE built successfully.\")\n",
    "    return lstm_rmse\n",
    "\n",
    "# Train LSTM model with metric RMSE\n",
    "def train_lstm_model_rmse(time_steps, input_sequences_train, next_step_targets_train):\n",
    "    logging.info(\"Starting training of LSTM model with RMSE metric...\")\n",
    "    lstm_model_rmse = build_lstm_model_rmse(time_steps, input_sequences_train.shape[2])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
    "    checkpoint = ModelCheckpoint('best_lstm_model_rmse.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "    lstm_model_rmse.fit(input_sequences_train, next_step_targets_train, epochs=20, validation_split=0.1, callbacks=[early_stopping, checkpoint])\n",
    "    lstm_model_rmse.save('lstm_model_rmse.keras')\n",
    "    logging.info(\"LSTM model with RMSE trained and saved successfully.\")\n",
    "    return lstm_model_rmse\n",
    "\n",
    "# Define GRU model with metric RMSE\n",
    "def build_gru_model_rmse(time_steps, input_shape):\n",
    "    logging.info(\"Building GRU model with RMSE metric...\")\n",
    "    gru_rmse = Sequential()\n",
    "    gru_rmse.add(GRU(64, return_sequences=True, input_shape=(time_steps, input_shape)))\n",
    "    gru_rmse.add(Dropout(0.2))\n",
    "    gru_rmse.add(GRU(64, return_sequences=False))\n",
    "    gru_rmse.add(Dense(input_shape, activation='sigmoid'))\n",
    "    gru_rmse.compile(optimizer='adam', loss='mean_squared_error', metrics=[RootMeanSquaredError()])\n",
    "    logging.info(\"GRU model with RMSE built successfully.\")\n",
    "    return gru_rmse\n",
    "    \n",
    "def build_gru_mae_acc(time_steps, num_features):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(128, return_sequences=True, input_shape=(time_steps, num_features)))\n",
    "    model.add(GRU(64))\n",
    "    model.add(Dense(1))  # Adjust output layer for your specific prediction task\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])  # Using MAE for loss\n",
    "    return model\n",
    "\n",
    "# Train GRU model with metric RMSE\n",
    "def train_gru_model_rmse(time_steps, input_sequences_train, next_step_targets_train):\n",
    "    logging.info(\"Starting training of GRU model with RMSE metric...\")\n",
    "    gru_model_rmse = build_gru_model_rmse(time_steps, input_sequences_train.shape[2])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
    "    checkpoint = ModelCheckpoint('best_gru_model_rmse.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "    gru_model_rmse.fit(input_sequences_train, next_step_targets_train, epochs=20, validation_split=0.1, callbacks=[early_stopping, checkpoint])\n",
    "    gru_model_rmse.save('gru_model_rmse.keras')\n",
    "    logging.info(\"GRU model with RMSE trained and saved successfully.\")\n",
    "    return gru_model_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b861e7e8-a3d8-4b95-8a77-c3d34d142fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 01:03:12,996 - INFO - Loading preprocessed data...\n",
      "2024-10-02 01:03:13,198 - INFO - Data loaded successfully.\n",
      "2024-10-02 01:03:13,199 - INFO - Starting training of LSTM model with accuracy metric...\n",
      "2024-10-02 01:03:13,200 - INFO - Building LSTM model with accuracy metric...\n",
      "C:\\Python3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-10-02 01:03:13,302 - INFO - LSTM model built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m770/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0083 - loss: 0.0485\n",
      "Epoch 1: val_loss improved from inf to 0.02581, saving model to best_lstm_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.0083 - loss: 0.0484 - val_accuracy: 0.0288 - val_loss: 0.0258\n",
      "Epoch 2/20\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0388 - loss: 0.0243\n",
      "Epoch 2: val_loss improved from 0.02581 to 0.02381, saving model to best_lstm_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.0389 - loss: 0.0243 - val_accuracy: 0.0686 - val_loss: 0.0238\n",
      "Epoch 3/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0475 - loss: 0.0197\n",
      "Epoch 3: val_loss improved from 0.02381 to 0.02237, saving model to best_lstm_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.0475 - loss: 0.0197 - val_accuracy: 0.0697 - val_loss: 0.0224\n",
      "Epoch 4/20\n",
      "\u001b[1m764/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0569 - loss: 0.0179\n",
      "Epoch 4: val_loss improved from 0.02237 to 0.02069, saving model to best_lstm_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.0569 - loss: 0.0179 - val_accuracy: 0.0832 - val_loss: 0.0207\n",
      "Epoch 5/20\n",
      "\u001b[1m765/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0648 - loss: 0.0158\n",
      "Epoch 5: val_loss improved from 0.02069 to 0.01789, saving model to best_lstm_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.0648 - loss: 0.0158 - val_accuracy: 0.0752 - val_loss: 0.0179\n",
      "Epoch 6/20\n",
      "\u001b[1m765/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0645 - loss: 0.0143\n",
      "Epoch 6: val_loss improved from 0.01789 to 0.01631, saving model to best_lstm_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.0645 - loss: 0.0143 - val_accuracy: 0.0744 - val_loss: 0.0163\n",
      "Epoch 7/20\n",
      "\u001b[1m765/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0621 - loss: 0.0139\n",
      "Epoch 7: val_loss improved from 0.01631 to 0.01609, saving model to best_lstm_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.0621 - loss: 0.0139 - val_accuracy: 0.0679 - val_loss: 0.0161\n",
      "Epoch 8/20\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0616 - loss: 0.0138\n",
      "Epoch 8: val_loss improved from 0.01609 to 0.01545, saving model to best_lstm_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.0616 - loss: 0.0138 - val_accuracy: 0.0737 - val_loss: 0.0155\n",
      "Epoch 9/20\n",
      "\u001b[1m770/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0625 - loss: 0.0131\n",
      "Epoch 9: val_loss improved from 0.01545 to 0.01513, saving model to best_lstm_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.0625 - loss: 0.0131 - val_accuracy: 0.0759 - val_loss: 0.0151\n",
      "Epoch 10/20\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0620 - loss: 0.0126\n",
      "Epoch 10: val_loss improved from 0.01513 to 0.01505, saving model to best_lstm_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.0620 - loss: 0.0126 - val_accuracy: 0.0788 - val_loss: 0.0150\n",
      "Epoch 11/20\n",
      "\u001b[1m769/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0592 - loss: 0.0123\n",
      "Epoch 11: val_loss improved from 0.01505 to 0.01452, saving model to best_lstm_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.0592 - loss: 0.0123 - val_accuracy: 0.0770 - val_loss: 0.0145\n",
      "Epoch 12/20\n",
      "\u001b[1m770/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0601 - loss: 0.0124\n",
      "Epoch 12: val_loss did not improve from 0.01452\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.0601 - loss: 0.0124 - val_accuracy: 0.0722 - val_loss: 0.0148\n",
      "Epoch 13/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0635 - loss: 0.0120\n",
      "Epoch 13: val_loss improved from 0.01452 to 0.01442, saving model to best_lstm_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.0635 - loss: 0.0120 - val_accuracy: 0.0602 - val_loss: 0.0144\n",
      "Epoch 14/20\n",
      "\u001b[1m765/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0600 - loss: 0.0122\n",
      "Epoch 14: val_loss improved from 0.01442 to 0.01425, saving model to best_lstm_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.0600 - loss: 0.0122 - val_accuracy: 0.0752 - val_loss: 0.0143\n",
      "Epoch 15/20\n",
      "\u001b[1m763/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0599 - loss: 0.0118\n",
      "Epoch 15: val_loss improved from 0.01425 to 0.01411, saving model to best_lstm_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.0599 - loss: 0.0118 - val_accuracy: 0.0766 - val_loss: 0.0141\n",
      "Epoch 16/20\n",
      "\u001b[1m769/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0682 - loss: 0.0115\n",
      "Epoch 16: val_loss did not improve from 0.01411\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.0682 - loss: 0.0115 - val_accuracy: 0.0890 - val_loss: 0.0148\n",
      "Epoch 17/20\n",
      "\u001b[1m764/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0667 - loss: 0.0117\n",
      "Epoch 17: val_loss did not improve from 0.01411\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.0667 - loss: 0.0117 - val_accuracy: 0.0686 - val_loss: 0.0142\n",
      "Epoch 18/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0654 - loss: 0.0116\n",
      "Epoch 18: val_loss improved from 0.01411 to 0.01394, saving model to best_lstm_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.0654 - loss: 0.0116 - val_accuracy: 0.0719 - val_loss: 0.0139\n",
      "Epoch 19/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0713 - loss: 0.0107\n",
      "Epoch 19: val_loss did not improve from 0.01394\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.0713 - loss: 0.0107 - val_accuracy: 0.0788 - val_loss: 0.0140\n",
      "Epoch 20/20\n",
      "\u001b[1m767/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0733 - loss: 0.0114\n",
      "Epoch 20: val_loss did not improve from 0.01394\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.0733 - loss: 0.0114 - val_accuracy: 0.0657 - val_loss: 0.0143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 01:05:07,935 - INFO - LSTM model trained and saved successfully.\n",
      "2024-10-02 01:05:07,936 - INFO - Starting training of GRU model with accuracy metric...\n",
      "2024-10-02 01:05:07,937 - INFO - Building GRU model with accuracy metric...\n",
      "2024-10-02 01:05:07,969 - INFO - GRU model built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m768/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0136 - loss: 0.0449\n",
      "Epoch 1: val_loss improved from inf to 0.02488, saving model to best_gru_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.0137 - loss: 0.0448 - val_accuracy: 0.0773 - val_loss: 0.0249\n",
      "Epoch 2/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0573 - loss: 0.0218\n",
      "Epoch 2: val_loss improved from 0.02488 to 0.02210, saving model to best_gru_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.0573 - loss: 0.0218 - val_accuracy: 0.0544 - val_loss: 0.0221\n",
      "Epoch 3/20\n",
      "\u001b[1m767/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0560 - loss: 0.0177\n",
      "Epoch 3: val_loss improved from 0.02210 to 0.01852, saving model to best_gru_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.0560 - loss: 0.0177 - val_accuracy: 0.0668 - val_loss: 0.0185\n",
      "Epoch 4/20\n",
      "\u001b[1m767/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0555 - loss: 0.0149\n",
      "Epoch 4: val_loss improved from 0.01852 to 0.01699, saving model to best_gru_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.0555 - loss: 0.0149 - val_accuracy: 0.0631 - val_loss: 0.0170\n",
      "Epoch 5/20\n",
      "\u001b[1m765/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0541 - loss: 0.0142\n",
      "Epoch 5: val_loss improved from 0.01699 to 0.01626, saving model to best_gru_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.0541 - loss: 0.0142 - val_accuracy: 0.0686 - val_loss: 0.0163\n",
      "Epoch 6/20\n",
      "\u001b[1m769/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0587 - loss: 0.0139\n",
      "Epoch 6: val_loss improved from 0.01626 to 0.01553, saving model to best_gru_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.0587 - loss: 0.0139 - val_accuracy: 0.0690 - val_loss: 0.0155\n",
      "Epoch 7/20\n",
      "\u001b[1m768/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0613 - loss: 0.0130\n",
      "Epoch 7: val_loss improved from 0.01553 to 0.01502, saving model to best_gru_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.0613 - loss: 0.0130 - val_accuracy: 0.0690 - val_loss: 0.0150\n",
      "Epoch 8/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0569 - loss: 0.0123\n",
      "Epoch 8: val_loss improved from 0.01502 to 0.01469, saving model to best_gru_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.0570 - loss: 0.0123 - val_accuracy: 0.0715 - val_loss: 0.0147\n",
      "Epoch 9/20\n",
      "\u001b[1m769/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0597 - loss: 0.0128\n",
      "Epoch 9: val_loss did not improve from 0.01469\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.0597 - loss: 0.0128 - val_accuracy: 0.0628 - val_loss: 0.0152\n",
      "Epoch 10/20\n",
      "\u001b[1m767/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0592 - loss: 0.0126\n",
      "Epoch 10: val_loss improved from 0.01469 to 0.01433, saving model to best_gru_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.0592 - loss: 0.0126 - val_accuracy: 0.0657 - val_loss: 0.0143\n",
      "Epoch 11/20\n",
      "\u001b[1m765/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0621 - loss: 0.0123\n",
      "Epoch 11: val_loss improved from 0.01433 to 0.01415, saving model to best_gru_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.0621 - loss: 0.0123 - val_accuracy: 0.0657 - val_loss: 0.0142\n",
      "Epoch 12/20\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0593 - loss: 0.0121\n",
      "Epoch 12: val_loss improved from 0.01415 to 0.01411, saving model to best_gru_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.0593 - loss: 0.0121 - val_accuracy: 0.0679 - val_loss: 0.0141\n",
      "Epoch 13/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0634 - loss: 0.0118\n",
      "Epoch 13: val_loss improved from 0.01411 to 0.01403, saving model to best_gru_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.0634 - loss: 0.0118 - val_accuracy: 0.0576 - val_loss: 0.0140\n",
      "Epoch 14/20\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0635 - loss: 0.0112\n",
      "Epoch 14: val_loss improved from 0.01403 to 0.01361, saving model to best_gru_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.0635 - loss: 0.0112 - val_accuracy: 0.0573 - val_loss: 0.0136\n",
      "Epoch 15/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0639 - loss: 0.0109\n",
      "Epoch 15: val_loss did not improve from 0.01361\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.0639 - loss: 0.0109 - val_accuracy: 0.0489 - val_loss: 0.0143\n",
      "Epoch 16/20\n",
      "\u001b[1m765/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0636 - loss: 0.0112\n",
      "Epoch 16: val_loss improved from 0.01361 to 0.01324, saving model to best_gru_model_acc.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.0636 - loss: 0.0112 - val_accuracy: 0.0628 - val_loss: 0.0132\n",
      "Epoch 17/20\n",
      "\u001b[1m767/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0618 - loss: 0.0110\n",
      "Epoch 17: val_loss did not improve from 0.01324\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.0618 - loss: 0.0110 - val_accuracy: 0.0642 - val_loss: 0.0140\n",
      "Epoch 18/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0641 - loss: 0.0109\n",
      "Epoch 18: val_loss did not improve from 0.01324\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.0640 - loss: 0.0109 - val_accuracy: 0.0514 - val_loss: 0.0137\n",
      "Epoch 19/20\n",
      "\u001b[1m765/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0665 - loss: 0.0100\n",
      "Epoch 19: val_loss did not improve from 0.01324\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.0664 - loss: 0.0100 - val_accuracy: 0.0423 - val_loss: 0.0192\n",
      "Epoch 20/20\n",
      "\u001b[1m769/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0608 - loss: 0.0124\n",
      "Epoch 20: val_loss did not improve from 0.01324\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.0608 - loss: 0.0124 - val_accuracy: 0.0646 - val_loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 01:07:05,320 - INFO - GRU model trained and saved successfully.\n",
      "2024-10-02 01:07:05,320 - INFO - Starting training of LSTM model with MAE metric...\n",
      "2024-10-02 01:07:05,321 - INFO - Building LSTM model with MAE metric...\n",
      "2024-10-02 01:07:05,360 - INFO - LSTM model with MAE built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m765/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0478 - mean_absolute_error: 0.1468\n",
      "Epoch 1: val_loss improved from inf to 0.02546, saving model to best_lstm_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0476 - mean_absolute_error: 0.1465 - val_loss: 0.0255 - val_mean_absolute_error: 0.0894\n",
      "Epoch 2/20\n",
      "\u001b[1m767/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0227 - mean_absolute_error: 0.0840\n",
      "Epoch 2: val_loss improved from 0.02546 to 0.02328, saving model to best_lstm_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0227 - mean_absolute_error: 0.0840 - val_loss: 0.0233 - val_mean_absolute_error: 0.0736\n",
      "Epoch 3/20\n",
      "\u001b[1m769/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0180 - mean_absolute_error: 0.0738\n",
      "Epoch 3: val_loss improved from 0.02328 to 0.01987, saving model to best_lstm_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0180 - mean_absolute_error: 0.0738 - val_loss: 0.0199 - val_mean_absolute_error: 0.0720\n",
      "Epoch 4/20\n",
      "\u001b[1m768/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0157 - mean_absolute_error: 0.0689\n",
      "Epoch 4: val_loss improved from 0.01987 to 0.01721, saving model to best_lstm_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0157 - mean_absolute_error: 0.0689 - val_loss: 0.0172 - val_mean_absolute_error: 0.0669\n",
      "Epoch 5/20\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0150 - mean_absolute_error: 0.0666\n",
      "Epoch 5: val_loss improved from 0.01721 to 0.01693, saving model to best_lstm_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0150 - mean_absolute_error: 0.0666 - val_loss: 0.0169 - val_mean_absolute_error: 0.0641\n",
      "Epoch 6/20\n",
      "\u001b[1m770/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0142 - mean_absolute_error: 0.0646\n",
      "Epoch 6: val_loss improved from 0.01693 to 0.01620, saving model to best_lstm_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0142 - mean_absolute_error: 0.0646 - val_loss: 0.0162 - val_mean_absolute_error: 0.0642\n",
      "Epoch 7/20\n",
      "\u001b[1m769/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0138 - mean_absolute_error: 0.0634\n",
      "Epoch 7: val_loss improved from 0.01620 to 0.01542, saving model to best_lstm_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0138 - mean_absolute_error: 0.0634 - val_loss: 0.0154 - val_mean_absolute_error: 0.0640\n",
      "Epoch 8/20\n",
      "\u001b[1m763/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0130 - mean_absolute_error: 0.0618\n",
      "Epoch 8: val_loss did not improve from 0.01542\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0130 - mean_absolute_error: 0.0618 - val_loss: 0.0157 - val_mean_absolute_error: 0.0647\n",
      "Epoch 9/20\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0126 - mean_absolute_error: 0.0607\n",
      "Epoch 9: val_loss improved from 0.01542 to 0.01522, saving model to best_lstm_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0126 - mean_absolute_error: 0.0607 - val_loss: 0.0152 - val_mean_absolute_error: 0.0592\n",
      "Epoch 10/20\n",
      "\u001b[1m767/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0127 - mean_absolute_error: 0.0607\n",
      "Epoch 10: val_loss improved from 0.01522 to 0.01442, saving model to best_lstm_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0127 - mean_absolute_error: 0.0607 - val_loss: 0.0144 - val_mean_absolute_error: 0.0610\n",
      "Epoch 11/20\n",
      "\u001b[1m769/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0123 - mean_absolute_error: 0.0596\n",
      "Epoch 11: val_loss did not improve from 0.01442\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0123 - mean_absolute_error: 0.0596 - val_loss: 0.0147 - val_mean_absolute_error: 0.0611\n",
      "Epoch 12/20\n",
      "\u001b[1m767/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0113 - mean_absolute_error: 0.0579\n",
      "Epoch 12: val_loss did not improve from 0.01442\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0113 - mean_absolute_error: 0.0579 - val_loss: 0.0145 - val_mean_absolute_error: 0.0597\n",
      "Epoch 13/20\n",
      "\u001b[1m764/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0117 - mean_absolute_error: 0.0584\n",
      "Epoch 13: val_loss improved from 0.01442 to 0.01406, saving model to best_lstm_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0117 - mean_absolute_error: 0.0584 - val_loss: 0.0141 - val_mean_absolute_error: 0.0600\n",
      "Epoch 14/20\n",
      "\u001b[1m767/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0111 - mean_absolute_error: 0.0571\n",
      "Epoch 14: val_loss did not improve from 0.01406\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0111 - mean_absolute_error: 0.0571 - val_loss: 0.0144 - val_mean_absolute_error: 0.0596\n",
      "Epoch 15/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0108 - mean_absolute_error: 0.0565\n",
      "Epoch 15: val_loss improved from 0.01406 to 0.01377, saving model to best_lstm_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0108 - mean_absolute_error: 0.0565 - val_loss: 0.0138 - val_mean_absolute_error: 0.0583\n",
      "Epoch 16/20\n",
      "\u001b[1m770/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0107 - mean_absolute_error: 0.0563\n",
      "Epoch 16: val_loss did not improve from 0.01377\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0107 - mean_absolute_error: 0.0563 - val_loss: 0.0139 - val_mean_absolute_error: 0.0632\n",
      "Epoch 17/20\n",
      "\u001b[1m770/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0108 - mean_absolute_error: 0.0562\n",
      "Epoch 17: val_loss did not improve from 0.01377\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0108 - mean_absolute_error: 0.0562 - val_loss: 0.0141 - val_mean_absolute_error: 0.0590\n",
      "Epoch 18/20\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0108 - mean_absolute_error: 0.0559\n",
      "Epoch 18: val_loss improved from 0.01377 to 0.01374, saving model to best_lstm_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0108 - mean_absolute_error: 0.0559 - val_loss: 0.0137 - val_mean_absolute_error: 0.0566\n",
      "Epoch 19/20\n",
      "\u001b[1m767/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0106 - mean_absolute_error: 0.0555\n",
      "Epoch 19: val_loss improved from 0.01374 to 0.01332, saving model to best_lstm_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0106 - mean_absolute_error: 0.0555 - val_loss: 0.0133 - val_mean_absolute_error: 0.0573\n",
      "Epoch 20/20\n",
      "\u001b[1m769/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0111 - mean_absolute_error: 0.0562\n",
      "Epoch 20: val_loss improved from 0.01332 to 0.01320, saving model to best_lstm_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0111 - mean_absolute_error: 0.0562 - val_loss: 0.0132 - val_mean_absolute_error: 0.0573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 01:08:54,610 - INFO - LSTM model with MAE trained and saved successfully.\n",
      "2024-10-02 01:08:54,610 - INFO - Starting training of GRU model with MAE metric...\n",
      "2024-10-02 01:08:54,611 - INFO - Building GRU model with MAE metric...\n",
      "2024-10-02 01:08:54,644 - INFO - GRU model with MAE built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m768/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0456 - mean_absolute_error: 0.1424\n",
      "Epoch 1: val_loss improved from inf to 0.02485, saving model to best_gru_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0456 - mean_absolute_error: 0.1422 - val_loss: 0.0249 - val_mean_absolute_error: 0.0812\n",
      "Epoch 2/20\n",
      "\u001b[1m767/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0224 - mean_absolute_error: 0.0836\n",
      "Epoch 2: val_loss improved from 0.02485 to 0.02290, saving model to best_gru_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0224 - mean_absolute_error: 0.0836 - val_loss: 0.0229 - val_mean_absolute_error: 0.0770\n",
      "Epoch 3/20\n",
      "\u001b[1m770/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0176 - mean_absolute_error: 0.0734\n",
      "Epoch 3: val_loss improved from 0.02290 to 0.02012, saving model to best_gru_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0176 - mean_absolute_error: 0.0734 - val_loss: 0.0201 - val_mean_absolute_error: 0.0740\n",
      "Epoch 4/20\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0161 - mean_absolute_error: 0.0694\n",
      "Epoch 4: val_loss improved from 0.02012 to 0.01813, saving model to best_gru_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0161 - mean_absolute_error: 0.0694 - val_loss: 0.0181 - val_mean_absolute_error: 0.0665\n",
      "Epoch 5/20\n",
      "\u001b[1m764/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0144 - mean_absolute_error: 0.0657\n",
      "Epoch 5: val_loss improved from 0.01813 to 0.01629, saving model to best_gru_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0144 - mean_absolute_error: 0.0657 - val_loss: 0.0163 - val_mean_absolute_error: 0.0658\n",
      "Epoch 6/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0139 - mean_absolute_error: 0.0643\n",
      "Epoch 6: val_loss improved from 0.01629 to 0.01576, saving model to best_gru_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0139 - mean_absolute_error: 0.0643 - val_loss: 0.0158 - val_mean_absolute_error: 0.0652\n",
      "Epoch 7/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0132 - mean_absolute_error: 0.0623\n",
      "Epoch 7: val_loss improved from 0.01576 to 0.01501, saving model to best_gru_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0132 - mean_absolute_error: 0.0623 - val_loss: 0.0150 - val_mean_absolute_error: 0.0627\n",
      "Epoch 8/20\n",
      "\u001b[1m765/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0132 - mean_absolute_error: 0.0619\n",
      "Epoch 8: val_loss improved from 0.01501 to 0.01431, saving model to best_gru_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0132 - mean_absolute_error: 0.0619 - val_loss: 0.0143 - val_mean_absolute_error: 0.0609\n",
      "Epoch 9/20\n",
      "\u001b[1m764/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0124 - mean_absolute_error: 0.0605\n",
      "Epoch 9: val_loss improved from 0.01431 to 0.01392, saving model to best_gru_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0124 - mean_absolute_error: 0.0605 - val_loss: 0.0139 - val_mean_absolute_error: 0.0595\n",
      "Epoch 10/20\n",
      "\u001b[1m765/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0128 - mean_absolute_error: 0.0607\n",
      "Epoch 10: val_loss improved from 0.01392 to 0.01391, saving model to best_gru_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0128 - mean_absolute_error: 0.0607 - val_loss: 0.0139 - val_mean_absolute_error: 0.0600\n",
      "Epoch 11/20\n",
      "\u001b[1m767/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0118 - mean_absolute_error: 0.0586\n",
      "Epoch 11: val_loss improved from 0.01391 to 0.01364, saving model to best_gru_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0118 - mean_absolute_error: 0.0586 - val_loss: 0.0136 - val_mean_absolute_error: 0.0594\n",
      "Epoch 12/20\n",
      "\u001b[1m763/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0118 - mean_absolute_error: 0.0582\n",
      "Epoch 12: val_loss did not improve from 0.01364\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0118 - mean_absolute_error: 0.0582 - val_loss: 0.0143 - val_mean_absolute_error: 0.0677\n",
      "Epoch 13/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0113 - mean_absolute_error: 0.0575\n",
      "Epoch 13: val_loss did not improve from 0.01364\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0113 - mean_absolute_error: 0.0575 - val_loss: 0.0147 - val_mean_absolute_error: 0.0608\n",
      "Epoch 14/20\n",
      "\u001b[1m769/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0118 - mean_absolute_error: 0.0584\n",
      "Epoch 14: val_loss did not improve from 0.01364\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0117 - mean_absolute_error: 0.0584 - val_loss: 0.0139 - val_mean_absolute_error: 0.0596\n",
      "Epoch 15/20\n",
      "\u001b[1m770/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0115 - mean_absolute_error: 0.0578\n",
      "Epoch 15: val_loss improved from 0.01364 to 0.01357, saving model to best_gru_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0115 - mean_absolute_error: 0.0578 - val_loss: 0.0136 - val_mean_absolute_error: 0.0611\n",
      "Epoch 16/20\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0110 - mean_absolute_error: 0.0569\n",
      "Epoch 16: val_loss improved from 0.01357 to 0.01325, saving model to best_gru_model_mae.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0110 - mean_absolute_error: 0.0569 - val_loss: 0.0133 - val_mean_absolute_error: 0.0570\n",
      "Epoch 17/20\n",
      "\u001b[1m769/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0107 - mean_absolute_error: 0.0558\n",
      "Epoch 17: val_loss did not improve from 0.01325\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0107 - mean_absolute_error: 0.0558 - val_loss: 0.0142 - val_mean_absolute_error: 0.0605\n",
      "Epoch 18/20\n",
      "\u001b[1m770/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0109 - mean_absolute_error: 0.0567\n",
      "Epoch 18: val_loss did not improve from 0.01325\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0109 - mean_absolute_error: 0.0567 - val_loss: 0.0133 - val_mean_absolute_error: 0.0588\n",
      "Epoch 19/20\n",
      "\u001b[1m767/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0104 - mean_absolute_error: 0.0554\n",
      "Epoch 19: val_loss did not improve from 0.01325\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0104 - mean_absolute_error: 0.0554 - val_loss: 0.0144 - val_mean_absolute_error: 0.0610\n",
      "Epoch 20/20\n",
      "\u001b[1m769/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0108 - mean_absolute_error: 0.0562\n",
      "Epoch 20: val_loss did not improve from 0.01325\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0108 - mean_absolute_error: 0.0562 - val_loss: 0.0189 - val_mean_absolute_error: 0.0710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 01:10:47,610 - INFO - GRU model with MAE trained and saved successfully.\n",
      "2024-10-02 01:10:47,611 - INFO - Starting training of LSTM model with RMSE metric...\n",
      "2024-10-02 01:10:47,611 - INFO - Building LSTM model with RMSE metric...\n",
      "2024-10-02 01:10:47,646 - INFO - LSTM model with RMSE built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m764/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0479 - root_mean_squared_error: 0.2151\n",
      "Epoch 1: val_loss improved from inf to 0.02507, saving model to best_lstm_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0477 - root_mean_squared_error: 0.2147 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1583\n",
      "Epoch 2/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0212 - root_mean_squared_error: 0.1454\n",
      "Epoch 2: val_loss improved from 0.02507 to 0.02246, saving model to best_lstm_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0212 - root_mean_squared_error: 0.1454 - val_loss: 0.0225 - val_root_mean_squared_error: 0.1499\n",
      "Epoch 3/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0170 - root_mean_squared_error: 0.1304\n",
      "Epoch 3: val_loss improved from 0.02246 to 0.01970, saving model to best_lstm_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0170 - root_mean_squared_error: 0.1304 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1404\n",
      "Epoch 4/20\n",
      "\u001b[1m769/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249\n",
      "Epoch 4: val_loss improved from 0.01970 to 0.01673, saving model to best_lstm_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0156 - root_mean_squared_error: 0.1249 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1293\n",
      "Epoch 5/20\n",
      "\u001b[1m765/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0148 - root_mean_squared_error: 0.1215\n",
      "Epoch 5: val_loss improved from 0.01673 to 0.01590, saving model to best_lstm_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0148 - root_mean_squared_error: 0.1215 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1261\n",
      "Epoch 6/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0136 - root_mean_squared_error: 0.1167\n",
      "Epoch 6: val_loss did not improve from 0.01590\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0136 - root_mean_squared_error: 0.1167 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1265\n",
      "Epoch 7/20\n",
      "\u001b[1m763/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0131 - root_mean_squared_error: 0.1144\n",
      "Epoch 7: val_loss improved from 0.01590 to 0.01492, saving model to best_lstm_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0131 - root_mean_squared_error: 0.1144 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1222\n",
      "Epoch 8/20\n",
      "\u001b[1m763/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0132 - root_mean_squared_error: 0.1150\n",
      "Epoch 8: val_loss did not improve from 0.01492\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0132 - root_mean_squared_error: 0.1150 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1229\n",
      "Epoch 9/20\n",
      "\u001b[1m767/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0128 - root_mean_squared_error: 0.1129\n",
      "Epoch 9: val_loss improved from 0.01492 to 0.01428, saving model to best_lstm_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0128 - root_mean_squared_error: 0.1129 - val_loss: 0.0143 - val_root_mean_squared_error: 0.1195\n",
      "Epoch 10/20\n",
      "\u001b[1m763/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0120 - root_mean_squared_error: 0.1096\n",
      "Epoch 10: val_loss improved from 0.01428 to 0.01391, saving model to best_lstm_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0120 - root_mean_squared_error: 0.1096 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1180\n",
      "Epoch 11/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0120 - root_mean_squared_error: 0.1096\n",
      "Epoch 11: val_loss did not improve from 0.01391\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0120 - root_mean_squared_error: 0.1096 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1199\n",
      "Epoch 12/20\n",
      "\u001b[1m768/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0115 - root_mean_squared_error: 0.1072\n",
      "Epoch 12: val_loss improved from 0.01391 to 0.01388, saving model to best_lstm_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0115 - root_mean_squared_error: 0.1072 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1178\n",
      "Epoch 13/20\n",
      "\u001b[1m770/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.1076\n",
      "Epoch 13: val_loss did not improve from 0.01388\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0116 - root_mean_squared_error: 0.1076 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1211\n",
      "Epoch 14/20\n",
      "\u001b[1m767/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0113 - root_mean_squared_error: 0.1065\n",
      "Epoch 14: val_loss improved from 0.01388 to 0.01341, saving model to best_lstm_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0113 - root_mean_squared_error: 0.1065 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1158\n",
      "Epoch 15/20\n",
      "\u001b[1m769/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0109 - root_mean_squared_error: 0.1043\n",
      "Epoch 15: val_loss improved from 0.01341 to 0.01331, saving model to best_lstm_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0109 - root_mean_squared_error: 0.1043 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1154\n",
      "Epoch 16/20\n",
      "\u001b[1m768/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0107 - root_mean_squared_error: 0.1036\n",
      "Epoch 16: val_loss did not improve from 0.01331\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0107 - root_mean_squared_error: 0.1036 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1176\n",
      "Epoch 17/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0114 - root_mean_squared_error: 0.1068\n",
      "Epoch 17: val_loss did not improve from 0.01331\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0114 - root_mean_squared_error: 0.1067 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1156\n",
      "Epoch 18/20\n",
      "\u001b[1m764/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0107 - root_mean_squared_error: 0.1037\n",
      "Epoch 18: val_loss did not improve from 0.01331\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0107 - root_mean_squared_error: 0.1037 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1162\n",
      "Epoch 19/20\n",
      "\u001b[1m763/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0109 - root_mean_squared_error: 0.1046\n",
      "Epoch 19: val_loss did not improve from 0.01331\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0109 - root_mean_squared_error: 0.1046 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1171\n",
      "Epoch 20/20\n",
      "\u001b[1m767/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0105 - root_mean_squared_error: 0.1025\n",
      "Epoch 20: val_loss did not improve from 0.01331\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0105 - root_mean_squared_error: 0.1025 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1161\n",
      "Epoch 20: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 01:12:37,267 - INFO - LSTM model with RMSE trained and saved successfully.\n",
      "2024-10-02 01:12:37,268 - INFO - Starting training of GRU model with RMSE metric...\n",
      "2024-10-02 01:12:37,269 - INFO - Building GRU model with RMSE metric...\n",
      "2024-10-02 01:12:37,299 - INFO - GRU model with RMSE built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0459 - root_mean_squared_error: 0.2107\n",
      "Epoch 1: val_loss improved from inf to 0.02456, saving model to best_gru_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0458 - root_mean_squared_error: 0.2104 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1567\n",
      "Epoch 2/20\n",
      "\u001b[1m768/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0220 - root_mean_squared_error: 0.1482\n",
      "Epoch 2: val_loss improved from 0.02456 to 0.02266, saving model to best_gru_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0220 - root_mean_squared_error: 0.1482 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1505\n",
      "Epoch 3/20\n",
      "\u001b[1m764/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335\n",
      "Epoch 3: val_loss improved from 0.02266 to 0.02123, saving model to best_gru_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1457\n",
      "Epoch 4/20\n",
      "\u001b[1m768/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0163 - root_mean_squared_error: 0.1278\n",
      "Epoch 4: val_loss improved from 0.02123 to 0.01944, saving model to best_gru_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0163 - root_mean_squared_error: 0.1278 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1394\n",
      "Epoch 5/20\n",
      "\u001b[1m769/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0146 - root_mean_squared_error: 0.1209\n",
      "Epoch 5: val_loss improved from 0.01944 to 0.01735, saving model to best_gru_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0146 - root_mean_squared_error: 0.1209 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1317\n",
      "Epoch 6/20\n",
      "\u001b[1m768/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0141 - root_mean_squared_error: 0.1188\n",
      "Epoch 6: val_loss improved from 0.01735 to 0.01639, saving model to best_gru_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0141 - root_mean_squared_error: 0.1188 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1280\n",
      "Epoch 7/20\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0131 - root_mean_squared_error: 0.1145\n",
      "Epoch 7: val_loss improved from 0.01639 to 0.01550, saving model to best_gru_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0131 - root_mean_squared_error: 0.1145 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1245\n",
      "Epoch 8/20\n",
      "\u001b[1m765/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140\n",
      "Epoch 8: val_loss improved from 0.01550 to 0.01504, saving model to best_gru_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1226\n",
      "Epoch 9/20\n",
      "\u001b[1m768/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0127 - root_mean_squared_error: 0.1126\n",
      "Epoch 9: val_loss did not improve from 0.01504\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0127 - root_mean_squared_error: 0.1126 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1244\n",
      "Epoch 10/20\n",
      "\u001b[1m768/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0125 - root_mean_squared_error: 0.1117\n",
      "Epoch 10: val_loss improved from 0.01504 to 0.01484, saving model to best_gru_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0125 - root_mean_squared_error: 0.1117 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1218\n",
      "Epoch 11/20\n",
      "\u001b[1m769/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103\n",
      "Epoch 11: val_loss improved from 0.01484 to 0.01423, saving model to best_gru_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0122 - root_mean_squared_error: 0.1103 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1193\n",
      "Epoch 12/20\n",
      "\u001b[1m768/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0118 - root_mean_squared_error: 0.1083\n",
      "Epoch 12: val_loss did not improve from 0.01423\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0118 - root_mean_squared_error: 0.1083 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1201\n",
      "Epoch 13/20\n",
      "\u001b[1m764/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081\n",
      "Epoch 13: val_loss improved from 0.01423 to 0.01394, saving model to best_gru_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0117 - root_mean_squared_error: 0.1081 - val_loss: 0.0139 - val_root_mean_squared_error: 0.1181\n",
      "Epoch 14/20\n",
      "\u001b[1m764/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0111 - root_mean_squared_error: 0.1054\n",
      "Epoch 14: val_loss did not improve from 0.01394\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0111 - root_mean_squared_error: 0.1054 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 15/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0113 - root_mean_squared_error: 0.1061\n",
      "Epoch 15: val_loss did not improve from 0.01394\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0113 - root_mean_squared_error: 0.1061 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1183\n",
      "Epoch 16/20\n",
      "\u001b[1m767/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0110 - root_mean_squared_error: 0.1049\n",
      "Epoch 16: val_loss did not improve from 0.01394\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0110 - root_mean_squared_error: 0.1049 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1186\n",
      "Epoch 17/20\n",
      "\u001b[1m766/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0107 - root_mean_squared_error: 0.1036\n",
      "Epoch 17: val_loss improved from 0.01394 to 0.01341, saving model to best_gru_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0107 - root_mean_squared_error: 0.1036 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1158\n",
      "Epoch 18/20\n",
      "\u001b[1m765/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0113 - root_mean_squared_error: 0.1063\n",
      "Epoch 18: val_loss improved from 0.01341 to 0.01332, saving model to best_gru_model_rmse.keras\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0113 - root_mean_squared_error: 0.1062 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1154\n",
      "Epoch 19/20\n",
      "\u001b[1m769/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0111 - root_mean_squared_error: 0.1051\n",
      "Epoch 19: val_loss did not improve from 0.01332\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0111 - root_mean_squared_error: 0.1051 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1187\n",
      "Epoch 20/20\n",
      "\u001b[1m765/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0108 - root_mean_squared_error: 0.1039\n",
      "Epoch 20: val_loss did not improve from 0.01332\n",
      "\u001b[1m771/771\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0108 - root_mean_squared_error: 0.1039 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 01:14:38,157 - INFO - GRU model with RMSE trained and saved successfully.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_lstm_model_r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m lstm_model_rmse_run \u001b[38;5;241m=\u001b[39m train_lstm_model_rmse(\u001b[38;5;241m10\u001b[39m, input_sequences_train, next_step_targets_train)\n\u001b[0;32m     14\u001b[0m gru_model_rmse_run \u001b[38;5;241m=\u001b[39m train_gru_model_rmse(\u001b[38;5;241m10\u001b[39m, input_sequences_train, next_step_targets_train)\n\u001b[1;32m---> 17\u001b[0m lstm_model_r2_run \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_lstm_model_r\u001b[49m(\u001b[38;5;241m10\u001b[39m, input_sequences_train, next_step_targets_train)\n\u001b[0;32m     18\u001b[0m gru_model_r2_run \u001b[38;5;241m=\u001b[39m train_gru_model_r(\u001b[38;5;241m10\u001b[39m, input_sequences_train, next_step_targets_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_lstm_model_r' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_sequences_train, next_step_targets_train = load_preprocessed_data()\n",
    "    \n",
    "    # Train both LSTM and GRU models\n",
    "    lstm_model_acc_run = train_lstm_model_acc(10, input_sequences_train, next_step_targets_train)\n",
    "    gru_model_acc_run = train_gru_model_acc(10, input_sequences_train, next_step_targets_train)\n",
    "\n",
    "\n",
    "    lstm_model_mae_run = train_lstm_model_mae(10, input_sequences_train, next_step_targets_train)\n",
    "    gru_model_mae_run = train_gru_model_mae(10, input_sequences_train, next_step_targets_train)\n",
    "\n",
    "\n",
    "    lstm_model_rmse_run = train_lstm_model_rmse(10, input_sequences_train, next_step_targets_train)\n",
    "    gru_model_rmse_run = train_gru_model_rmse(10, input_sequences_train, next_step_targets_train)\n",
    "\n",
    "    # undefined for now\n",
    "    # lstm_model_r2_run = train_lstm_model_r(10, input_sequences_train, next_step_targets_train)\n",
    "    # gru_model_r2_run = train_gru_model_r(10, input_sequences_train, next_step_targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9be20d-2681-4cfd-834d-faa0516894f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
